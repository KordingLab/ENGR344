{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KordingLab/ENGR344/blob/master/tutorials/W3D1_What_should_we_do_when_data_has_problems/W3D1_Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "GwG32kd0jf8H"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Tutorial 3: Missing Data\n",
        "**Week 3: What should we do when data has problems?**\n",
        "\n",
        "**Content creators**: Rob Lindgren\n",
        "\n",
        "**Content reviewers**: Konrad Kording, Keervani Kandala\n",
        "\n",
        "**Content modifiers**: ---\n",
        "\n",
        "**Modified Content reviewer**: ---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "mngEsmgIjf8J"
      },
      "source": [
        "___\n",
        "# Tutorial Objectives\n",
        "\n",
        "*Estimated timing of tutorial: __ minutes*\n",
        "\n",
        "This is tutorial 3 in a 3-part series on how to handle data that has problems. In this tutorial, we will learn about missing data: what problems does it pose, how it is represented in base Python, NumPy, and Pandas, how to identify them, and how to remove or fill them. By the end of this tutorial, you will be able to:\n",
        "\n",
        "- Explain the problems caused by missing values\n",
        "- Explain the different types of missing values\n",
        "- Identify missing values in NumPy and Pandas\n",
        "- Remove missing values with NumPy and Pandas\n",
        "- Fill in missing values with Pandas using a single value or a linear estimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "zK3D5SfMjf8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "8a51199d-4727-45f5-acc1-224347a3b0fc",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"854\"\n",
              "            height=\"480\"\n",
              "            src=\"https://mfr.ca-1.osf.io/render?url=https://osf.io/hncv7/?direct%26mode=render%26action=download%26mode=render\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fd1594eb190>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# @title Tutorial slides\n",
        " \n",
        "# @markdown These are the slides for the videos in all tutorials today\n",
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/hncv7/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "GvEi-BMsjf8L"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "execution": {},
        "id": "YY7HrpSyjf8L"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create different kinds of missing data\n",
        "\n",
        "def mcar(df_in, var_list, true_probs):\n",
        "  \"\"\"Replaces values in the columns named by var_list with None such that\n",
        "  the data in those columns are missing-completely-at-random.\n",
        "\n",
        "  Args:\n",
        "    df_in (DataFrame): Pandas DataFrame containing all variables in var_list.\n",
        "    var_list (list of strings): List of variable names to which missing values\n",
        "      will be assigned.\n",
        "    true_prob (list of numbers): Each entry in true_prop indicates the probability\n",
        "      of a missing value being assigned. It is the same length as var_list and\n",
        "      the first entry corresponds to the first variable, the second to the second,\n",
        "      etc. All entries must be between 0 and 1 inclusive.\n",
        "\n",
        "  Returns:\n",
        "    The DataFrame df_in, but with all variables in var_list now MCAR.\n",
        "  \"\"\"\n",
        "  df = df_in.copy()\n",
        "\n",
        "  n = df.shape[0]\n",
        "  rng = np.random.RandomState(2)\n",
        "  for var, t in zip(var_list, true_probs):\n",
        "    f = 1-t\n",
        "    mask = rng.choice([True, False], size=n, p=[t, f])\n",
        "    df.loc[mask, [var]] = None\n",
        "\n",
        "  return df\n",
        "\n",
        "def mar(df_in, var_list, true_probs, fact_var, fact_val):\n",
        "  \"\"\"Replaces values in the columns named by var_list with None such that\n",
        "  the data in those columns are missing-at-random.\n",
        "\n",
        "  Args:\n",
        "    df_in (DataFrame): Pandas DataFrame containing all variables in var_list.\n",
        "    var_list (list of strings): List of variable names to which missing values\n",
        "      will be assigned.\n",
        "    true_prob (list of numbers): Each entry in true_prop indicates the probability\n",
        "      of a missing value being assigned. It is the same length as var_list and\n",
        "      the first entry corresponds to the first variable, the second to the second,\n",
        "      etc. All entries must be between 0 and 1 inclusive.\n",
        "    fact_var (string): Name of a factor variable in df_in that will determine \n",
        "      which observations are assignmed missing values and which are not.\n",
        "    fact_val (dtype of df_in[fact_var]): The value of fact_var for which missing\n",
        "      values will be assigned. \n",
        "\n",
        "  Returns:\n",
        "    The DataFrame df_in, but with all variables in var_list now MCAR.\n",
        "  \"\"\"\n",
        "  df = df_in.copy()\n",
        "  df_sub = df[df[fact_var] == fact_val].copy()\n",
        "  df = df[df[fact_var] != fact_val].copy()\n",
        "\n",
        "  n = df_sub.shape[0]\n",
        "  rng = np.random.RandomState(2)\n",
        "\n",
        "  for var, t in zip(var_list, true_probs):\n",
        "    f = 1-t\n",
        "    mask = rng.choice([True, False], size=n, p=[t, f])\n",
        "    df_sub.loc[mask, var] = None \n",
        "\n",
        "  df = df.append(df_sub)\n",
        "\n",
        "  return df\n",
        "\n",
        "def mnar(df_in):\n",
        "  \"\"\"Replaces values in the 'Highway mpg' column with None such that\n",
        "  the data in those columns are missing-not-at-random.\n",
        "\n",
        "  Args:\n",
        "    df_in (DataFrame): Pandas DataFrame containing all variables in var_list.\n",
        "\n",
        "  Returns:\n",
        "    The DataFrame df_in, but with all 'Highway mpg' now MCAR.\n",
        "  \"\"\"\n",
        "  df_bias = df_in.copy()\n",
        "  df_bias = df.copy()\n",
        "  #df_bias.loc[(df_bias['Highway mpg'] > 25) & (df_bias['Horsepower'] < 350), 'Highway mpg'] = None\n",
        "  df_bias.loc[df_bias['Highway mpg'] > 25, 'Highway mpg'] = None\n",
        "\n",
        "  return df_bias\n",
        "\n",
        "def choose_missing(df_in):\n",
        "\n",
        "  choice_dict = {'mcar' : mcar(df_in, var_list=['Highway mpg'], true_probs=[0.2]),\n",
        "                 'mar' : mar(df_in, var_list=['Highway mpg'], true_probs=[0.2], fact_var='Driveline', fact_val='All-wheel drive'),\n",
        "                 'mnar' : mnar(df_in)}\n",
        "\n",
        "  rng = np.random.RandomState(1)\n",
        "  fn_order = rng.choice(['mcar', 'mar', 'mnar'], size=3, replace=False)\n",
        "\n",
        "  output_df = {'data' : {'A' : None, 'B' : None, 'C' : None},\n",
        "               'name' : {'A' : None, 'B' : None, 'C' : None}}\n",
        "  for fn,letter in zip(fn_order, ['A', 'B', 'C']):\n",
        "    output_df['data'][letter] = choice_dict[fn]\n",
        "    output_df['name'][letter] = fn\n",
        "\n",
        "  return output_df"
      ],
      "metadata": {
        "id": "c4ZQYm8vb4GD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plotting Functions\n",
        "\n",
        "# Solution\n",
        "def plt_cars(df):\n",
        "  \"\"\"Plot histograms of 'Horsepower' and ' Highway mpg' from the Cars dataset, \n",
        "  as well as a scatterplot of 'Horsepower' vs. 'Highway mpg'.\n",
        "\n",
        "  Args:\n",
        "    df (DataFrame): Cars dataset, with variables 'Horsepower' and 'Highway 'mpg'.\n",
        "\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "\n",
        "  # Compute means\n",
        "  means = df.mean()\n",
        "\n",
        "  # Create figure and axes objects\n",
        "  fig_a, (ax1, ax2) = plt.subplots(1, 2)\n",
        "  \n",
        "  # Visualize 'Horsepower'\n",
        "  ax1.hist('Horsepower', data=df)\n",
        "  ax1.set_xlabel(\"Horsepower\")\n",
        "  ax1.set_ylabel(\"Number of vehicles\")\n",
        "  ax1.axvline(means['Horsepower'], color='Orange')\n",
        "\n",
        "  # Visualize 'Highway mpg'\n",
        "  ax2.hist('Highway mpg', data=df)\n",
        "  ax2.set_xlabel(\"Highway mpg\")\n",
        "  ax2.set_ylabel(\"Number of vehicles\")\n",
        "  ax2.axvline(means['Highway mpg'], color='Orange')\n",
        "  print(fig_a)\n",
        "\n",
        "  print('\\n')\n",
        "  \n",
        "  # Visualize the relationship between 'Horsepower' and 'Highway mpg'\n",
        "  fig_b, ax = plt.subplots(1, 1)\n",
        "  ax.scatter('Horsepower', 'Highway mpg', data=df)\n",
        "  ax.set_xlabel('Horsepower')\n",
        "  ax.set_ylabel('Highway mpg')\n",
        "  print(fig_b)\n",
        "\n",
        "def plt_reg(df_in, x, y, y_pred):\n",
        "  \"\"\"Creates a scatterplot of x and y from df_in, then overlays a lineplot\n",
        "  of x and y_pred over top.\n",
        "\n",
        "  Args:\n",
        "    df_in (DataFrame): Dataset with variables labeled x and y.\n",
        "    x (string): Name of variable to be plotted on x-axis.\n",
        "    y (string): Name of variable to be plotted on y-axis.\n",
        "    y_pred (array-like): Predicted y values resulting from regression.\n",
        "\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  df = df_in.copy()\n",
        "  fig, ax = plt.subplots(1, )\n",
        "  ax.scatter(x, y, data=df)\n",
        "  ax.plot(df[x], y_pred, color='red', linewidth=3)\n",
        "  print(fig)\n"
      ],
      "metadata": {
        "id": "OrOmn-xaNlug",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper function for linear regression\n",
        "def regress(df_in, x_lab, y_lab):\n",
        "  \"\"\"Performs linear regression of y_lab on x_lab variables from \n",
        "  dataframe df_in. Returns results in a dictionary.\n",
        "\n",
        "  Args:\n",
        "    df_in (DataFrame): Pandas DataFrame with variables named\n",
        "      x_lab and y_lab.\n",
        "    x_lab (string): Name of independent variable for regression.\n",
        "    y_lab (string): Name of dependent variable for regression.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of the following form...\n",
        "      {'prediction' : predicted_values,\n",
        "      'intercept' : intercept\n",
        "      'coef' : coefficient}\n",
        "  \"\"\"\n",
        "  \n",
        "  # Takes a dataframe and two variable names from the dataframe\n",
        "  # and returns a dictionary with the regression results.\n",
        "\n",
        "  # Output dictionary looks like this...\n",
        "  # {'prediction' : predicted_values,\n",
        "  #  'intercept' : intercept\n",
        "  #  'coef' : coefficient}\n",
        "  df = df_in.copy()\n",
        "\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "\n",
        "  x = df.loc[:, [x_lab]].values.reshape(-1, 1)  # values converts it into a numpy array\n",
        "  y = df.loc[:, [y_lab]].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\n",
        "  reg = LinearRegression()  # create object for the class\n",
        "  reg.fit(x, y)  # perform linear regression\n",
        "  y_pred = reg.predict(x)  # make predictions\n",
        "\n",
        "  out = {'prediction' : reg.predict(x),\n",
        "        'intercept' : reg.intercept_[0],\n",
        "        'coef' : reg.coef_[0][0]}\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "dDi7CbuiT3LL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper functions to detect and remove outliers\n",
        "def detect_outliers(df_in, thresh):\n",
        "  df = df_in.copy()\n",
        "  df_z = (df - df.mean()) / df.std()\n",
        "  df_out = np.abs(df_z) > thresh\n",
        "  return df_out\n",
        "  \n",
        "def remove_outliers(df_in, thresh):\n",
        "  df = df_in.copy()\n",
        "  df_out = df[np.logical_not(detect_outliers(df, thresh)).all(axis=1)]\n",
        "  return df_out"
      ],
      "metadata": {
        "id": "jSkYM1ROYOFp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "loUlF0Sojf8T"
      },
      "source": [
        "---\n",
        "# Prepare Data\n",
        "\n",
        "*Estimated timing to here from start of tutorial: 90 min*\n",
        "\n",
        "In this tutorial we will learn how to identify and handline both outliers and missing values in our data while we continue to investigate the Cars dataset.\n",
        "\n",
        "Once again, let's load the Cars dataset, subset it, and verify that we got the subset that we expected.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = 'https://raw.githubusercontent.com/RealTimeWeb/datasets/master/datasets/csv/cars/cars.csv'\n",
        "df = pd.read_csv(data_url)[['ID', 'Driveline', 'Horsepower', 'Highway mpg']]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SSbi1PfxOqSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use our `remove_outliers()` function from the last tutorial to remove all data points that are 3 or more standard deviations from the mean of their respective distributions."
      ],
      "metadata": {
        "id": "VWB0DKtrX3L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df = remove_outliers(df, 3)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "q45twXvaYLr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: What problems do missing values pose?\n",
        "\n",
        "Missing values cause three key problems in data analysis:\n",
        "- Reduction of statistical power\n",
        "- Biased results\n",
        "- Reduced representativeness of samples"
      ],
      "metadata": {
        "id": "KpEhByCcP5W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#insert video"
      ],
      "metadata": {
        "id": "l_i0B12q377N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discuss missing not at random (MNAR) as it relates to your field."
      ],
      "metadata": {
        "id": "UuKHV77N7MEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1.1: Reduction of statistical power"
      ],
      "metadata": {
        "id": "cT4VdAGnO-si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical power is the likelihood of rejecting a null hypothesis when the null hypothesis is false, i.e. when you *should* reject the null hypothesis. Missing values, when not filled in somehow, reduce sample size which, in turn, reduces statistical power.\n",
        "\n",
        "Even a small number of missing values per variable can be a serious issue when our analysis requires multiple variables. Take the following dataset, for example:"
      ],
      "metadata": {
        "id": "Zr5oKjJY0LBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_df = pd.DataFrame({'Speed' : [1, None, 3, 4, 5],\n",
        "                       'Horsepower' : [6, 7, None, 9, 10],\n",
        "                       'Mpg' : [11, 12, 13, None, 15]})\n",
        "bad_df"
      ],
      "metadata": {
        "id": "UW5s37DL4b1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each column is missing just one value, but if we require all three for our analysis, then we are left with only two complete observations."
      ],
      "metadata": {
        "id": "bv1qlIw-4xAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_df.dropna()"
      ],
      "metadata": {
        "id": "uyNhz_eE45yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1.2: Bias and reduced representativeness of samples.\n",
        "\n",
        "There may or may not be a pattern to the missingness of our data. The presence of a pattern will determine whether and how missing values result in a less representative sample and bias our results. Missing data can be:\n",
        "\n",
        "- **Missing completely at random (MCAR):** Data is MCAR when the missingness of values is unrelated to what is being measured. Surveys may get lost in the mail, a faulty instrument may occassionally fail to register a measurement independently of what is being measured, and lab samples may be damaged before they can be tested. If data that is truly MCAR, the sample obtained will still be representative and estimates will be unbiased. \n",
        "\n",
        "- **Missing at random (MAR):** Data is MAR when the missingness of values is related variables in our dataset *other than* the variable with the missing value. If surveys are predictably lost in the mail in one zipcode but not others (and the zipcode is in our data), then the missing values are MAR. Similarly, if the faulty instrument more frequently fails on hot days rather than cold days (and we have a variable indicating hot and cold days in our data), those values are also MAR. As long as we properly account for the pattern with which our MAR data is missing, we can get a representative sample and an unbiased result.\n",
        "\n",
        "- **Missing not at random (MNAR):** Data is MNAR when missingness is related to what is being measured. If our faulty instrument is a thermometer that regularly fails to record a temperature on hot days, those values would be MNAR. This is the most problematic type of missing data. The only way to get an unbiased result is to either go out and retrieve the missing data or accurately model it.\n"
      ],
      "metadata": {
        "id": "37-uS99h6j6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: How are missing values represented?"
      ],
      "metadata": {
        "id": "_seuJeqmQCEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2.1: In general\n",
        "\n",
        "There are two ways to represent missing values:\n",
        "- Masking\n",
        "- Sentinel Values"
      ],
      "metadata": {
        "id": "44byGF5ia5gC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masking is typically performed using a boolean array with `True` entries indicating that value is missing and `False` entries indicating that it is not. The below mask tells us that the first and third entries are missing.\n",
        "\n",
        "```\n",
        "mask = [True, False, True, False, False]\n",
        "```"
      ],
      "metadata": {
        "id": "TnNpCPwrVuo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentinel values are often data-specific, such as extreme values that would not be appropriate to the thing being measured. For example, the US Census counts the total number of people in a household. This number can never be negative, so -1 is a reasonable choice to represent missing values for this particular variable. \n",
        "\n",
        "```\n",
        "hh_members = [2, 1, -1, 3, 5, -1, 2]\n",
        "```\n",
        "\n",
        "Sentinel values can also be conventional, such as the `NaN` (not-a-number) value used by NumPy. `NaN` is a special value in the IEEE floating-point specification set aside for undefined values."
      ],
      "metadata": {
        "id": "A0oheZZCWKtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.arange(10.0)\n",
        "test[2] = np.NaN\n",
        "test"
      ],
      "metadata": {
        "id": "eWzjvlDXYuMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are trade-offs to each of these methods\n",
        "\n",
        "- **Masking** requires the allocation of an additional array, which reduces storage and computational overhead. The degree to which this is a problem will depend on how large the allocated array needs to be.\n",
        "- **Sentinel values in general** require extra logic for computations. For example, you can’t use a sum() function on a variable for which missing values are represented with a -1 without some extra steps.\n",
        "- Using **extreme values** as sentinels reduces the range of values you can represent in your data.\n",
        "- **Special values** like NaN are not available for all data types (there is no NaN for integers). Python libraries like NumPy and Pandas continue to update their handling of missing values to account for this, so it’s worth keeping an eye out for changes to missing value representation.\n"
      ],
      "metadata": {
        "id": "62LgTo_Ba8kW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2.2: How NumPy and Pandas represent missing values\n",
        "\n",
        "There are two representations of missing values in Python and its libraries NumPy and Pandas:\n",
        "- `None`\n",
        "- `NaN`"
      ],
      "metadata": {
        "id": "l2hT64Kzao5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`None` in Python is of data type 'object', the most general data type. It can only be used in arrays that are also of type 'object'."
      ],
      "metadata": {
        "id": "zOy2gGFdc3Kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1, 2, None, 4])\n",
        "arr"
      ],
      "metadata": {
        "id": "V_YyhtcSdKiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`None`: Base Python uses None to represent missing data\n",
        "None is an object, so it can only be used in arrays with data type “object.” \n",
        "These arrays can hold a variety of data types including integers, floats, and strings, therefore they can’t really be optimized for performing calculations quickly. \n",
        "If you provide an array with a None object to a function like sum(), it will raise an error.\n",
        "\n",
        "`NaN`: This is where NumPy comes in. NumPy relies on the IEEE floating-point NaN (not-a-number) np.nan\n",
        "Because it is part of the IEEE 754 standard, it is recognized by most systems. \n",
        "This supports much faster operations.\n",
        "This also means that aggregations are well-defined over NumPy arrays containing np.nan, so you can use np.sum() (which return np.nan if there is any np.nan in the input) or np.nansum() (which ignores the missing values). \n"
      ],
      "metadata": {
        "id": "abg_CFT1ckNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Identifying and missing values"
      ],
      "metadata": {
        "id": "0ow1sJjgQVIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3.1: Identifying missing values\n",
        "\n",
        "NumPy and Pandas provide us with three handy methods for uncovering missing values: \n",
        "- `np.isnan()`\n",
        "- `df.isnull()`\n",
        "- `df.notnull()`\n",
        "\n",
        "All three of them return a boolean array indicating either the presence (in the case of the first two) or absence (the last one) of missing values."
      ],
      "metadata": {
        "id": "Bo8P19az9XXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returning to our NumPy array from earlier with the NaN at index 2..."
      ],
      "metadata": {
        "id": "3y-LDbOEg2_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.arange(10.0)\n",
        "test[2] = np.NaN\n",
        "test"
      ],
      "metadata": {
        "id": "Alx4gx46g5lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can identify the location of the missing value using `np.isnull()`."
      ],
      "metadata": {
        "id": "x35jpbdJhSy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missings = np.isnan(test)\n",
        "missings"
      ],
      "metadata": {
        "id": "RfBxJe85hbps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can use this boolean array along with `np.logical_not()`, which applies the logical 'not' operator across elements of an array, to remove the missing value."
      ],
      "metadata": {
        "id": "7Xz0wqXHhvfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test[np.logical_not(missings)]"
      ],
      "metadata": {
        "id": "FWwBoDUBiBcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the `pd.isnull()` and `pd.notnull` operators on our Cars dataset. Notice that this is a method of the DataFrame object, so for the dataframe `df` you call it using `df.isnull()`."
      ],
      "metadata": {
        "id": "4dkZv6stiQZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull()"
      ],
      "metadata": {
        "id": "ZsobR10OiXfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.notnull()"
      ],
      "metadata": {
        "id": "oG_xIdX7inIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coding Exercise 3.1: Count missing values by variable\n",
        "\n",
        "Pandas DataFrames also have a `sum()` method that we can call by appending it to the DataFrame name, as in `df.sum()`. If you use the `sum()` method on a boolean array, Python will treat `True` values as 1 and `False` values as 0, allowing you to easily count the number of missing values in each column of a DateFrame.\n",
        "\n",
        "*Exercise objective: print the number of missing values in each column of Cars dataset.*\n"
      ],
      "metadata": {
        "id": "CpdlpBwFRvcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################################\n",
        "## TODO for students: Use df.isnull() and df.sum() to count missing values.\n",
        "raise NotImplementedError('student exercise: count missing values')\n",
        "###########################################################################\n",
        "\n",
        "print(...) # Hint: you can do this in one line by combining both methods"
      ],
      "metadata": {
        "id": "gZ-ZexMkg4VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to_remove Solution\n",
        "\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "FzCIYcr0qTpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coding Exercise 3.2: Can you detect MCAR, MAR, and MNAR?\n",
        "\n",
        "In the first cell below, we create three different DataFrames: `df_A`, `df_B`, and `df_C`.\n",
        "\n",
        "- One of these DataFrames has 'Highway mpg' values missing-completely-at-random\n",
        "- Another has 'Highway mpg' values missing-at-random with respect to the 'Driveline' variable, i.e., the missing values in 'Highway mpg' are somehow predictable from 'Driveline'\n",
        "- And the third has 'Highway mpg' values missing-not-at-random, i.e., the missing values in 'Highway mpg' depend on real 'Highway mpg' and are not predictable from this dataset at all\n",
        "\n",
        "Using the following tools, figure out which of the DataFrames below is MCAR, which is MAR, and which MNAR. \n",
        "- `plt_cars()`: Visualization is your friend!\n",
        "- You can use a structure like `df.isnull().groupby(df['Driveline']).sum()` to calculate the number of the missing values for each value of Driveline.\n"
      ],
      "metadata": {
        "id": "39FlKI0ipErX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_df = choose_missing(df)\n",
        "df_A = out_df['data']['A']\n",
        "df_B = out_df['data']['B']\n",
        "df_C = out_df['data']['C']"
      ],
      "metadata": {
        "id": "02SEotxDVXaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################################\n",
        "## TODO for students: Identify the MCAR, MAR, and MNAR DataFrames.\n",
        "raise NotImplementedError('Identify the MCAR, MAR, and MNAR DataFrames')\n",
        "###########################################################################"
      ],
      "metadata": {
        "id": "NNp3SOlfWZfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to_remove Solution\n",
        "\n",
        "# There is no obvious pattern to the distribution of missing values across \n",
        "# values of Driveline\n",
        "print(df_A.isnull().groupby(df_A['Driveline']).sum())\n",
        "\n",
        "# Both the histograms and scatterplot look as expected\n",
        "plt_cars(df_A)\n",
        "\n",
        "# Conclusion: df_A is likely MCAR\n"
      ],
      "metadata": {
        "id": "3Rtd_iBxfSkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to_remove Solution contd.\n",
        "\n",
        "# The missing values seem to be concentrated in Front-wheel drive\n",
        "print(df_B.isnull().groupby(df_B['Driveline']).sum())\n",
        "\n",
        "# The histogram for 'Highway mpg' is entirely cut off above 25\n",
        "# This would mean the missingness of values depends on 'Highway mpg',\n",
        "# i.e., all values greater than 25 are missing, so df_B must be MNAR\n",
        "plt_cars(df_B)\n",
        "\n",
        "# Conclusion: df_B is MNAR"
      ],
      "metadata": {
        "id": "HlaRU_SKgtwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to_remove Solution contd.\n",
        "\n",
        "# This looks like good evidence that df_C is MAR: There is a relationship between Driveline and missing values\n",
        "print(df_C.isnull().groupby(df_C['Driveline']).sum())\n",
        "\n",
        "# The histograms and scatterplot look roughly as expected, so these don't tell us much\n",
        "plt_cars(df_C)\n",
        "\n",
        "# Conclusion: df_C is MAR"
      ],
      "metadata": {
        "id": "G11ACVIcgyJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coding Exercise 3.2 Answer\n",
        "\n",
        "Running the cell below will print out the answer to Coding Exercise 3.2.\n"
      ],
      "metadata": {
        "id": "Ai4TAvR-aphj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for key in out_df['name']:\n",
        "  print('DataFrame df_' + key + ' is: ' + out_df['name'][key])"
      ],
      "metadata": {
        "id": "znOR_TuJa2N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Handling missing values\n",
        "\n",
        "Pandas provides methods dropping rows with missing values, filling missing values with a constant, and interpolating missing values using one of several estimation methods.\n",
        "\n",
        "- `df.dropna()`\n",
        "- `df.fillna()`\n",
        "- `df.interpolate()`"
      ],
      "metadata": {
        "id": "CGPgyvvl9fAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert video"
      ],
      "metadata": {
        "id": "49Hn58DO8ITT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LqhJZdQV_Tox"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-kKkWcBqjf8V"
      },
      "source": [
        "### Coding Exercise 3.2: Estimate Missing Data\n",
        "\n",
        "In this exercise we're going to compare different methods of filling missing data using `df.fillna()`.\n",
        "\n",
        "- Fill in with the mean.\n",
        "- Fill in with a linear estimate."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################################\n",
        "## TODO for students: Complete the following functions for filling in \n",
        "## missing data, one using the mean and one using a linear estimate.\n",
        "raise NotImplementedError('student exercise: functions for filling in data')\n",
        "###########################################################################\n",
        "\n",
        "def fill_with_mean(df_in):\n",
        "  df = df_in.copy()\n",
        "\n",
        "  # Calculate the means of each column\n",
        "  means = ...\n",
        "\n",
        "  # Fill the missing values in df with the means calculated above\n",
        "  # Hint: use inplace=True to modify the existing DataFrame without creating a \n",
        "  # new one\n",
        "  ...\n",
        "  return df\n",
        "\n",
        "def fill_with_lin(df_in):\n",
        "  df = df_in.copy()\n",
        "\n",
        "  # Sort values by 'Horsepower'\n",
        "  # Hint: use the sort_values() method for dataframes\n",
        "  ... \n",
        "\n",
        "  # Interpolate using the linear method\n",
        "  # Set the limit_direction parameter to 'both'\n",
        "  ...\n",
        "  return df"
      ],
      "metadata": {
        "id": "gfITv0_77tlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "RfPBo4dvjf8W"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "def fill_with_mean(df_in):\n",
        "  df = df_in.copy()\n",
        "\n",
        "  # Calculate the means of each column\n",
        "  means = df.mean()\n",
        "\n",
        "  # Fill the missing values in df with the means calculated above\n",
        "  df.fillna(means, inplace=True) \n",
        "\n",
        "  return df.fillna(df.mean())\n",
        "\n",
        "def fill_with_lin(df_in):\n",
        "  df = df_in.copy()\n",
        "\n",
        "  # Sort values by 'Horsepower'\n",
        "  # Hint: use the sort_values() method for dataframes\n",
        "  df.sort_values('Horsepower', inplace=True)\n",
        "\n",
        "  # Interpolate using the linear method\n",
        "  # Set the limit_direction parameter to 'both'\n",
        "  df.interpolate(method='linear', inplace=True, limit_direction='both')\n",
        "  \n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use our new functions and plot the results."
      ],
      "metadata": {
        "id": "0Gveogfg90Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill with mean and plot\n",
        "df_fill_m = fill_with_mean(df)\n",
        "plt_cars(df_fill_m)\n",
        "\n",
        "# Fill with linear estimate and plot\n",
        "df_fill_lin = fill_with_lin(df)\n",
        "plt_cars(df_fill_lin)\n"
      ],
      "metadata": {
        "id": "DsWlfFPJ94Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...And let's see how different methods of filling missing values affect our regression results."
      ],
      "metadata": {
        "id": "t9PQBzx9VRhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling with the mean\n",
        "reg_mean = regress(df_fill_m, 'Horsepower', 'Highway mpg') \n",
        "plt_reg(df_fill_m, 'Horsepower', 'Highway mpg', reg_mean['prediction'])\n",
        "print('Intercept = ' + str(reg_mean['intercept']))\n",
        "print('Coefficient = ' + str(reg_mean['coef']))"
      ],
      "metadata": {
        "id": "DvWFwdL3VdBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling with linear estimate\n",
        "reg_lin = regress(df_fill_lin, 'Horsepower', 'Highway mpg') \n",
        "plt_reg(df_fill_lin, 'Horsepower', 'Highway mpg', reg_lin['prediction'])\n",
        "print('Intercept = ' + str(reg_lin['intercept']))\n",
        "print('Coefficient = ' + str(reg_lin['coef']))"
      ],
      "metadata": {
        "id": "dw1C7ijnVxtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Discussion\n",
        "In this tutorial we have seen a broad range of problems and solutions for cases where we have missing data. Let us talk about the relevant issues. What can we handle as data scientists? What requires better data?\n",
        "\n",
        "And how does all this relate to causality?\n"
      ],
      "metadata": {
        "id": "ypSKrHOOQva1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit\n",
        "Take the weekly survey/quiz and also submit your notebooks there. (Click the ?D logo below!)\n",
        "\n",
        "<a href=\"https://airtable.com/shrJhXIeslRire1iD\"><img src=\"https://github.com/KordingLab/ENGR344/blob/master/tutorials/static_344/SubmitButton.jpg?raw=1\" alt=\"button link to survey\" style=\"width:410px\"></a>"
      ],
      "metadata": {
        "id": "h4pY-c2NAvrP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Module_3_Tutorial3",
      "provenance": [],
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}